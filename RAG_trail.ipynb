{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data_path = 'data.csv'\n",
    "df = pd.read_csv(data_path, encoding=\"ISO-8859-1\")\n",
    "\n",
    "# Data Cleaning\n",
    "df.dropna(subset=['Description'], inplace=True)  # Remove rows with missing descriptions\n",
    "df['Description'] = df['Description'].str.lower()  # Convert to lowercase\n",
    "df['Description'] = df['Description'].str.replace(r'[^a-zA-Z0-9 ]', '', regex=True)  # Remove special characters\n",
    "# elimination of NaN values\n",
    "df.dropna(inplace=True)\n",
    "# elimination of duplicate rows\n",
    "df.drop_duplicates(inplace=True)\n",
    "# elimination of cancelled orders\n",
    "df = df[~df['InvoiceNo'].str.startswith('C')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>536365</td>\n",
       "      <td>85123A</td>\n",
       "      <td>white hanging heart tlight holder</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>2.55</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>536365</td>\n",
       "      <td>71053</td>\n",
       "      <td>white metal lantern</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>536365</td>\n",
       "      <td>84406B</td>\n",
       "      <td>cream cupid hearts coat hanger</td>\n",
       "      <td>8</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>2.75</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>536365</td>\n",
       "      <td>84029G</td>\n",
       "      <td>knitted union flag hot water bottle</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>536365</td>\n",
       "      <td>84029E</td>\n",
       "      <td>red woolly hottie white heart</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  InvoiceNo StockCode                          Description  Quantity  \\\n",
       "0    536365    85123A    white hanging heart tlight holder         6   \n",
       "1    536365     71053                  white metal lantern         6   \n",
       "2    536365    84406B       cream cupid hearts coat hanger         8   \n",
       "3    536365    84029G  knitted union flag hot water bottle         6   \n",
       "4    536365    84029E        red woolly hottie white heart         6   \n",
       "\n",
       "      InvoiceDate  UnitPrice  CustomerID         Country  \n",
       "0  12/1/2010 8:26       2.55     17850.0  United Kingdom  \n",
       "1  12/1/2010 8:26       3.39     17850.0  United Kingdom  \n",
       "2  12/1/2010 8:26       2.75     17850.0  United Kingdom  \n",
       "3  12/1/2010 8:26       3.39     17850.0  United Kingdom  \n",
       "4  12/1/2010 8:26       3.39     17850.0  United Kingdom  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Basic RAG </h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# # Load the minilmv6-l2 model\n",
    "# model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# Save the model locally\n",
    "model_save_path = r'C:\\Users\\prana\\OneDrive\\Desktop\\IITHyderabd\\PR-RAG\\MiniLM-L6-v2'\n",
    "# model.save(model_save_path)\n",
    "\n",
    "# Load the model from the saved path\n",
    "loaded_model = SentenceTransformer(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index created and descriptions added.\n"
     ]
    }
   ],
   "source": [
    "# Encode the product descriptions\n",
    "descriptions = df['Description'].tolist()\n",
    "encoded_descriptions = loaded_model.encode(descriptions)\n",
    "\n",
    "# Create a FAISS index\n",
    "dimension = encoded_descriptions.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "\n",
    "# Add the encoded descriptions to the index\n",
    "index.add(encoded_descriptions)\n",
    "\n",
    "# Store the mapping of row indices\n",
    "row_mapping = {i: idx for i, idx in enumerate(df.index)}\n",
    "\n",
    "print(\"FAISS index created and descriptions added.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS database size: 392732\n"
     ]
    }
   ],
   "source": [
    "print(f\"FAISS database size: {index.ntotal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index and row mapping saved.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the FAISS index\n",
    "faiss.write_index(index, 'faiss_index.bin')\n",
    "\n",
    "# Save the row mapping\n",
    "with open('row_mapping.pkl', 'wb') as f:\n",
    "    pickle.dump(row_mapping, f)\n",
    "\n",
    "print(\"FAISS index and row mapping saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search results:\n",
      "french blue metal door sign 2\n",
      "ladies  gentlemen metal sign\n",
      "set3 book box green gingham flower \n",
      "french kitchen sign blue metal\n",
      "hanging fairy cake decoration\n"
     ]
    }
   ],
   "source": [
    "# Define the search query\n",
    "search_query = \"vintage mug\"\n",
    "\n",
    "# Encode the search query using the loaded model\n",
    "encoded_query = loaded_model.encode([search_query])\n",
    "\n",
    "# Perform the search\n",
    "k = 5  # Number of nearest neighbors to retrieve\n",
    "distances, indices = index.search(encoded_query, k)\n",
    "\n",
    "# Retrieve the corresponding descriptions from the dataframe\n",
    "results = [df.iloc[row_mapping[idx]]['Description'] for idx in indices[0]]\n",
    "\n",
    "print(\"Search results:\")\n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search results:\n",
      "cream cupid hearts coat hanger\n",
      "wooden picture frame white finish\n",
      "lunch box i love london\n",
      "love heart pocket warmer\n",
      "small popcorn holder\n"
     ]
    }
   ],
   "source": [
    "from agno.agent import Agent\n",
    "\n",
    "class SearchAgent(Agent):\n",
    "    def __init__(self, index, row_mapping, model):\n",
    "        super().__init__()\n",
    "        self.index = index\n",
    "        self.row_mapping = row_mapping\n",
    "        self.model = model\n",
    "\n",
    "    def search(self, query, k=5):\n",
    "        encoded_query = self.model.encode([query])\n",
    "        distances, indices = self.index.search(encoded_query, k)\n",
    "        results = [df.iloc[self.row_mapping[idx]]['Description'] for idx in indices[0]]\n",
    "        return results\n",
    "\n",
    "# Initialize the search agent\n",
    "search_agent = SearchAgent(index=index, row_mapping=row_mapping, model=loaded_model)\n",
    "\n",
    "# Define a function to use the agent for searching\n",
    "def search_with_agent(query, k=5):\n",
    "    return search_agent.search(query, k)\n",
    "\n",
    "# Example usage\n",
    "query = \"CREAM CUPID HEARTS COAT HANGER\"\n",
    "results = search_with_agent(query)\n",
    "print(\"Search results:\")\n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As I lay in bed, I couldn't shake the feeling that something was watching me from the shadows. It wasn't until I heard my own voice whisper \"goodnight\" back to me that I realized I wasn't alone.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from agno.agent import Agent, RunResponse  # noqa\n",
    "from agno.models.ollama import Ollama\n",
    "\n",
    "agent = Agent(model=Ollama(id=\"llama3.2\"), markdown=True)\n",
    "\n",
    "# Get the response in a variable\n",
    "run: RunResponse = agent.run(\"Share a 2 sentence horror story\")\n",
    "print(run.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Agentic RAG </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from agno.agent import Agent, RunResponse\n",
    "from agno.embedder.ollama import OllamaEmbedder\n",
    "from agno.models.ollama import Ollama\n",
    "from agno.vectordb.pgvector import PgVector\n",
    "from agno.knowledge.text import TextKnowledgeBase\n",
    "\n",
    "# Load product descriptions\n",
    "csv_file = \"data.csv\"  # Update with your actual CSV file\n",
    "df = pd.read_csv(csv_file, encoding=\"ISO-8859-1\")\n",
    "# Data Cleaning\n",
    "df.dropna(subset=['Description'], inplace=True)  # Remove rows with missing descriptions\n",
    "df['Description'] = df['Description'].str.lower()  # Convert to lowercase\n",
    "df['Description'] = df['Description'].str.replace(r'[^a-zA-Z0-9 ]', '', regex=True)# Remove special characters\n",
    "\n",
    "# elimination of NaN values\n",
    "df.dropna(inplace=True)\n",
    "# elimination of duplicate rows\n",
    "df.drop_duplicates(inplace=True)\n",
    "# elimination of cancelled orders\n",
    "df = df[~df['InvoiceNo'].str.startswith('C')]\n",
    "products = list(set(df['Description'].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database connection\n",
    "db_url = \"postgresql+psycopg://postgres:pranav2004$@localhost:5433/ProductDescription\"  # Update with your actual DB URL\n",
    "\n",
    "# Initialize Vector Database\n",
    "vector_db = PgVector(\n",
    "    table_name=\"product_descriptions\",\n",
    "    db_url=db_url,\n",
    "    embedder=OllamaEmbedder(id=\"llama3.2\", dimensions=3072),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3867/3867 [02:25<00:00, 26.56it/s]\n"
     ]
    }
   ],
   "source": [
    "from agno.knowledge.text import Document\n",
    "from tqdm import tqdm\n",
    "# Ensure vector_db has an embedder\n",
    "embedder = vector_db.embedder  \n",
    "\n",
    "documents = []\n",
    "for description in tqdm(products):\n",
    "    \n",
    "    # Generate embedding manually\n",
    "    embedding = embedder.get_embedding(description)  # Convert text to vector\n",
    "\n",
    "    # Create document with content and embedding\n",
    "    doc = Document(content=description)\n",
    "    doc.embedding = embedding  # Assign embedding manually\n",
    "\n",
    "    documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db.insert(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"LOVE HEART NAPKIN BOX\"\n",
    "# Convert query text into an embedding\n",
    "query_embedding = vector_db.embedder.get_embedding(query)  # Pass the query as a list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(content='embossed heart trinket box', id='72c18181960b87cbc4ad317eeebf349b', name=None, meta_data={}, embedder=OllamaEmbedder(dimensions=3072, id='llama3.2', host=None, timeout=None, options=None, client_kwargs=None, ollama_client=None), embedding=array([-0.19260289, -0.5875256 ,  4.287101  , ..., -0.22511965,\n",
      "        0.5104131 ,  0.34725544], dtype=float32), usage=None, reranking_score=None), Document(content='strawberry ceramic trinket box', id='3c7b4fe2bb925e97cc115f65624b5181', name=None, meta_data={}, embedder=OllamaEmbedder(dimensions=3072, id='llama3.2', host=None, timeout=None, options=None, client_kwargs=None, ollama_client=None), embedding=array([ 0.13428666,  0.04675705,  4.0765805 , ...,  0.37095943,\n",
      "       -0.0974075 ,  0.63025624], dtype=float32), usage=None, reranking_score=None), Document(content='red gingham rose jewellery box', id='d5bb33a814efa5144c2851a5d209adbf', name=None, meta_data={}, embedder=OllamaEmbedder(dimensions=3072, id='llama3.2', host=None, timeout=None, options=None, client_kwargs=None, ollama_client=None), embedding=array([ 0.11304502, -0.46992147,  4.405523  , ...,  0.2930416 ,\n",
      "        0.1260777 ,  0.28739977], dtype=float32), usage=None, reranking_score=None), Document(content='sweetheart ceramic trinket box', id='fc0c43f2b7cf76f0a07e6bf6ae294ba6', name=None, meta_data={}, embedder=OllamaEmbedder(dimensions=3072, id='llama3.2', host=None, timeout=None, options=None, client_kwargs=None, ollama_client=None), embedding=array([-0.32102695,  0.01765696,  4.4942713 , ..., -0.15741023,\n",
      "       -0.14049007,  0.47200987], dtype=float32), usage=None, reranking_score=None), Document(content='tea time tea set in gift box', id='44e7c201cbbba6e3bccaced4c37c55ea', name=None, meta_data={}, embedder=OllamaEmbedder(dimensions=3072, id='llama3.2', host=None, timeout=None, options=None, client_kwargs=None, ollama_client=None), embedding=array([-0.53579825,  0.2781722 ,  3.5226912 , ..., -0.28452766,\n",
      "       -0.22608589,  0.4378137 ], dtype=float32), usage=None, reranking_score=None)]\n"
     ]
    }
   ],
   "source": [
    "results = vector_db.search(query, limit=5)  # Retrieve top 5 similar descriptions\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading knowledge base                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO    \u001b[0m Loading knowledge base                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load product descriptions into the vector DB\n",
    "knowledge_base = TextKnowledgeBase(\n",
    "    texts=products,  # Ensure \"Description\" column exists\n",
    "    vector_db=vector_db,\n",
    "    path=\"product_descriptions\"\n",
    ")\n",
    "\n",
    "# Store embeddings (only run once or when updating)\n",
    "knowledge_base.load(recreate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextKnowledgeBase(reader=TextReader(chunk=True, chunk_size=3000, separators=['\\n', '\\n\\n', '\\r', '\\r\\n', '\\n\\r', '\\t', ' ', '  '], chunking_strategy=<agno.document.chunking.fixed.FixedSizeChunking object at 0x0000025EEAD3C790>), vector_db=<agno.vectordb.pgvector.pgvector.PgVector object at 0x0000025EE0A095D0>, num_documents=5, optimize_on=1000, chunking_strategy=<agno.document.chunking.fixed.FixedSizeChunking object at 0x0000025EEAD3C790>, path='product_descriptions', formats=['.txt'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knowledge_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Agent with Vector DB Knowledge\n",
    "agent = Agent(\n",
    "    model=Ollama(id=\"llama3.2\"),\n",
    "    knowledge=knowledge_base,\n",
    "    show_tool_calls=True,  # Enable to see tool calls\n",
    ")\n",
    "\n",
    "# Function to interact with the agent\n",
    "def ask_agent(query):\n",
    "    \n",
    "    print(\"\\nAgent's Response:\")\n",
    "    run: RunResponse = agent.run(query)\n",
    "    print(run.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agent's Response:\n",
      " - Running: search_knowledge_base(query=Recommendations for products similar to LOVE HEART NAPKIN BOX)\n",
      "\n",
      "Based on the LOVE HEART NAPKIN BOX, here are some similar tool recommendations:\n",
      "\n",
      "1. **LOVE HEART TEA SET IN GIFT BOX**: A beautifully crafted tea set with heart-shaped designs, perfect for a lovely afternoon tea.\n",
      "2. **DIAMANTE PEN SET IN GIFT BOX**: A set of elegant pens with diamante details, ideal for writing love letters or signing special occasions.\n",
      "3. **HEART-SHAPED TEA TIME TRAY IN GIFT BOX**: A charming tea time tray with a heart-shaped design, perfect for serving delicate finger foods and teas.\n",
      "\n",
      "These recommendations offer a mix of elegance, romance, and whimsy, similar to the LOVE HEART NAPKIN BOX.\n"
     ]
    }
   ],
   "source": [
    "ask_agent(\"return a recommendation similar to LOVE HEART NAPKIN BOX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agent's Response:\n",
      " - Running: search_knowledge_base(query=RECOMMENDATION FOR LOVE HEART NAPKIN BOX SIMILAR PRODUCTS)\n",
      "\n",
      "Based on the tool call response, I recommend the \"Pig Mug in Two Colour Designs\" as a similar product to the LOVE HEART NAPKIN BOX. This mug is a popular item that can add a touch of personality and whimsy to any room.\n"
     ]
    }
   ],
   "source": [
    "ask_agent(\"return a recommendation similar to LOVE HEART NAPKIN BOX, use the knowledge base only to provide the answer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agent's Response:\n",
      " - Running: search_knowledge_base(query=GUMBALL COAT RACK)\n",
      "\n",
      "Based on the tool call response, I recommend the \"TRELLIS COAT RACK\" as an alternative to the GUMBALL COAT RACK. The Trellis Coat Rack has a similar aesthetic and functionality to the Gumball Coat Rack, with a unique and stylish design that can add a touch of personality to any entryway or hallway.\n"
     ]
    }
   ],
   "source": [
    "ask_agent(\"return a recommendation similar to GUMBALL COAT RACK, use the knowledge base only to provide the answer\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
